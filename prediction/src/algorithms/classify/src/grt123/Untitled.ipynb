{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'generators'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d28b0bf6ca46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgtr123_preprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlum_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'generators'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../../..')\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.preprocess.gtr123_preprocess import lum_trans, resample, generators\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from ..classification_model import ClassificationModel\n",
    "from classification_model import ClassificationModel\n",
    "\n",
    "\"\"\"\"\n",
    "Classification model from team gtr123\n",
    "Code adapted from https://github.com/lfz/DSB2017\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Model(ClassificationModel):\n",
    "    def __init__(self, init_model=True, pull_size=10, batch_size=32, data_format=None):\n",
    "        super(Model, self).__init__(init_model, pull_size, batch_size, data_format)\n",
    "\n",
    "        self.config = dict()\n",
    "\n",
    "        self.config['crop_size'] = [96, 96, 96]\n",
    "        self.config['scaleLim'] = [0.85, 1.15]\n",
    "        self.config['radiusLim'] = [6, 100]\n",
    "\n",
    "        self.config['stride'] = 4\n",
    "\n",
    "        self.config['detect_th'] = 0.05\n",
    "        self.config['conf_th'] = -1\n",
    "        self.config['nms_th'] = 0.05\n",
    "        self.config['filling_value'] = 160\n",
    "\n",
    "        self.config['startepoch'] = 20\n",
    "        self.config['lr_stage'] = np.array([50, 100, 140, 160])\n",
    "        self.config['lr'] = [0.01, 0.001, 0.0001, 0.00001]\n",
    "        self.config['miss_ratio'] = 1\n",
    "        self.config['miss_thresh'] = 0.03\n",
    "        self.config['anchors'] = [10, 30, 60]\n",
    "\n",
    "\n",
    "        self.data_generator = generators.DataGenerator(featurewise_center=True,\n",
    "                                                       featurewise_std_normalization=True,\n",
    "                                                       rotation_range=20,\n",
    "                                                       shift_range=.1,\n",
    "                                                       zoom_lower=.8,\n",
    "                                                       zoom_upper=1.2,\n",
    "                                                       zoom_independent=False,\n",
    "                                                       fill_mode='nearest',\n",
    "                                                       preprocessing_function=None)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def feed(self, annotations, sampling_pure, sampling_cancerous):\n",
    "        pass\n",
    "\n",
    "    def init_model(self):\n",
    "        class PostRes(nn.Module):\n",
    "            \"\"\" \"\"\"\n",
    "\n",
    "            def __init__(self, n_in, n_out, stride=1):\n",
    "                super(PostRes, self).__init__()\n",
    "                self.conv1 = nn.Conv3d(n_in, n_out, kernel_size=3, stride=stride, padding=1)\n",
    "                self.bn1 = nn.BatchNorm3d(n_out)\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "                self.conv2 = nn.Conv3d(n_out, n_out, kernel_size=3, padding=1)\n",
    "                self.bn2 = nn.BatchNorm3d(n_out)\n",
    "\n",
    "                if stride != 1 or n_out != n_in:\n",
    "                    self.shortcut = nn.Sequential(\n",
    "                        nn.Conv3d(n_in, n_out, kernel_size=1, stride=stride),\n",
    "                        nn.BatchNorm3d(n_out))\n",
    "                else:\n",
    "                    self.shortcut = None\n",
    "\n",
    "            def forward(self, x):\n",
    "\n",
    "                residual = x\n",
    "                if self.shortcut is not None:\n",
    "                    residual = self.shortcut(x)\n",
    "                out = self.conv1(x)\n",
    "                out = self.bn1(out)\n",
    "                out = self.relu(out)\n",
    "                out = self.conv2(out)\n",
    "                out = self.bn2(out)\n",
    "\n",
    "                out += residual\n",
    "                out = self.relu(out)\n",
    "                return out\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            \"\"\" \"\"\"\n",
    "\n",
    "            def __init__(self):\n",
    "                super(Net, self).__init__()\n",
    "                # The first few layers consumes the most memory, so use simple\n",
    "                # convolution to save memory. Call these layers preBlock, i.e., before\n",
    "                # the residual blocks of later layers.\n",
    "                self.preBlock = nn.Sequential(\n",
    "                    nn.Conv3d(1, 24, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm3d(24),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv3d(24, 24, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm3d(24),\n",
    "                    nn.ReLU(inplace=True))\n",
    "\n",
    "                # 3 poolings, each pooling downsamples the feature map by a factor 2.\n",
    "                # 3 groups of blocks. The first block of each group has one pooling.\n",
    "                num_blocks_forw = [2, 2, 3, 3]\n",
    "                num_blocks_back = [3, 3]\n",
    "                self.featureNum_forw = [24, 32, 64, 64, 64]\n",
    "                self.featureNum_back = [128, 64, 64]\n",
    "\n",
    "                for i in range(len(num_blocks_forw)):\n",
    "                    blocks = []\n",
    "\n",
    "                    for j in range(num_blocks_forw[i]):\n",
    "                        if j == 0:\n",
    "                            blocks.append(PostRes(self.featureNum_forw[i], self.featureNum_forw[i + 1]))\n",
    "                        else:\n",
    "                            blocks.append(PostRes(self.featureNum_forw[i + 1], self.featureNum_forw[i + 1]))\n",
    "\n",
    "                    setattr(self, 'forw' + str(i + 1), nn.Sequential(*blocks))\n",
    "\n",
    "                for i in range(len(num_blocks_back)):\n",
    "                    blocks = []\n",
    "\n",
    "                    for j in range(num_blocks_back[i]):\n",
    "                        if j == 0:\n",
    "                            if i == 0:\n",
    "                                addition = 3\n",
    "                            else:\n",
    "                                addition = 0\n",
    "\n",
    "                            blocks.append(PostRes(self.featureNum_back[i + 1] + self.featureNum_forw[i + 2] + addition,\n",
    "                                                  self.featureNum_back[i]))\n",
    "                        else:\n",
    "                            blocks.append(PostRes(self.featureNum_back[i], self.featureNum_back[i]))\n",
    "\n",
    "                    setattr(self, 'back' + str(i + 2), nn.Sequential(*blocks))\n",
    "\n",
    "                self.maxpool1 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "                self.maxpool2 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "                self.maxpool3 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "                self.maxpool4 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "                self.unmaxpool1 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "                self.unmaxpool2 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "\n",
    "                self.path1 = nn.Sequential(\n",
    "                    nn.ConvTranspose3d(64, 64, kernel_size=2, stride=2),\n",
    "                    nn.BatchNorm3d(64),\n",
    "                    nn.ReLU(inplace=True))\n",
    "\n",
    "                self.path2 = nn.Sequential(\n",
    "                    nn.ConvTranspose3d(64, 64, kernel_size=2, stride=2),\n",
    "                    nn.BatchNorm3d(64),\n",
    "                    nn.ReLU(inplace=True))\n",
    "\n",
    "                self.drop = nn.Dropout3d(p=0.2, inplace=False)\n",
    "                self.output = nn.Sequential(nn.Conv3d(self.featureNum_back[0], 64, kernel_size=1),\n",
    "                                            nn.ReLU(),\n",
    "                                            # nn.Dropout3d(p = 0.3),\n",
    "                                            nn.Conv3d(64, 5 * len(self.config['anchors']), kernel_size=1))\n",
    "\n",
    "            def forward(self, x, coord):\n",
    "                \"\"\"\n",
    "\n",
    "                Args:\n",
    "                  x:\n",
    "                  coord:\n",
    "\n",
    "                Returns:\n",
    "\n",
    "                \"\"\"\n",
    "                out = self.preBlock(x)  # 16\n",
    "                out_pool, indices0 = self.maxpool1(out)\n",
    "                out1 = self.forw1(out_pool)  # 32\n",
    "                out1_pool, indices1 = self.maxpool2(out1)\n",
    "                out2 = self.forw2(out1_pool)  # 64\n",
    "                # out2 = self.drop(out2)\n",
    "                out2_pool, indices2 = self.maxpool3(out2)\n",
    "                out3 = self.forw3(out2_pool)  # 96\n",
    "                out3_pool, indices3 = self.maxpool4(out3)\n",
    "                out4 = self.forw4(out3_pool)  # 96\n",
    "                # out4 = self.drop(out4)\n",
    "\n",
    "                rev3 = self.path1(out4)\n",
    "                comb3 = self.back3(torch.cat((rev3, out3), 1))  # 96+96\n",
    "                # comb3 = self.drop(comb3)\n",
    "                rev2 = self.path2(comb3)\n",
    "\n",
    "                feat = self.back2(torch.cat((rev2, out2, coord), 1))  # 64+64\n",
    "                comb2 = self.drop(feat)\n",
    "                out = self.output(comb2)\n",
    "                size = out.size()\n",
    "                out = out.view(out.size(0), out.size(1), -1)\n",
    "                # out = out.transpose(1, 4).transpose(1, 2).transpose(2, 3).contiguous()\n",
    "                out = out.transpose(1, 2).contiguous().view(size[0], size[2], size[3], size[4],\n",
    "                                                            len(self.config['anchors']), 5)\n",
    "                # out = out.view(-1, 5)\n",
    "                return feat, out\n",
    "\n",
    "        class CaseNet(nn.Module):\n",
    "            \"\"\"The classification Net from the gtr123 team - part of the Winning algorithm for DSB2017\"\"\"\n",
    "\n",
    "            def __init__(self):\n",
    "                super(CaseNet, self).__init__()\n",
    "                self.NoduleNet = Net()\n",
    "                self.fc1 = nn.Linear(128, 64)\n",
    "                self.fc2 = nn.Linear(64, 1)\n",
    "                self.pool = nn.MaxPool3d(kernel_size=2)\n",
    "                self.dropout = nn.Dropout(0.5)\n",
    "                self.baseline = nn.Parameter(torch.Tensor([-30.0]).float())\n",
    "                self.Relu = nn.ReLU()\n",
    "\n",
    "            def forward(self, xlist, coordlist):\n",
    "                \"\"\"\n",
    "\n",
    "                Args:\n",
    "                  xlist:  Image of size n x k x 1x 96 x 96 x 96\n",
    "                  coordlist: Coordinates of size n x k x 3 x 24 x 24 x 24\n",
    "\n",
    "                Returns:\n",
    "\n",
    "                \"\"\"\n",
    "                xsize = xlist.size()\n",
    "                corrdsize = coordlist.size()\n",
    "                print(xsize)\n",
    "                # xlist = xlist.view(-1,xsize[2],xsize[3],xsize[4],xsize[5])\n",
    "                # coordlist = coordlist.view(-1,corrdsize[2],corrdsize[3],corrdsize[4],corrdsize[5])\n",
    "\n",
    "                noduleFeat, nodulePred = self.NoduleNet(xlist, coordlist)\n",
    "                nodulePred = nodulePred.contiguous().view(corrdsize[0], corrdsize[1], -1)\n",
    "\n",
    "                featshape = noduleFeat.size()  # nk x 128 x 24 x 24 x24\n",
    "                centerFeat = self.pool(noduleFeat[:, :, featshape[2] // 2 - 1:featshape[2] // 2 + 1,\n",
    "                                       featshape[3] // 2 - 1:featshape[3] // 2 + 1,\n",
    "                                       featshape[4] // 2 - 1:featshape[4] // 2 + 1])\n",
    "                centerFeat = centerFeat[:, :, 0, 0, 0]\n",
    "                out = self.dropout(centerFeat)\n",
    "                out = self.Relu(self.fc1(out))\n",
    "                out = torch.sigmoid(self.fc2(out))\n",
    "                out = out.view(xsize[0], xsize[1])\n",
    "                base_prob = torch.sigmoid(self.baseline)\n",
    "                casePred = 1 - torch.prod(1 - out, dim=1) * (1 - base_prob.expand(out.size()[0]))\n",
    "                return nodulePred, casePred, out\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _ct_preprocess(self, ct_path):\n",
    "        pass\n",
    "\n",
    "    def predict(self, candidates, model_path=None):\n",
    "        pass\n",
    "\n",
    "    def train(self, annotations, train_val_split):\n",
    "        pass\n",
    "\n",
    "    def _batch_process(self, batch, labels):\n",
    "        pass\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SimpleCrop(object):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.crop_size = self.config['crop_size']\n",
    "        self.scaleLim = self.config['scaleLim']\n",
    "        self.radiusLim = self.config['radiusLim']\n",
    "        self.stride = self.config['stride']\n",
    "        self.filling_value = self.config['filling_value']\n",
    "\n",
    "    def __call__(self, imgs, target):\n",
    "        crop_size = np.array(self.crop_size).astype('int')\n",
    "\n",
    "        start = (target[:3] - crop_size / 2).astype('int')\n",
    "        pad = [[0, 0]]\n",
    "\n",
    "        for i in range(3):\n",
    "            if start[i] < 0:\n",
    "                leftpad = -start[i]\n",
    "                start[i] = 0\n",
    "            else:\n",
    "                leftpad = 0\n",
    "            if start[i] + crop_size[i] > imgs.shape[i + 1]:\n",
    "                rightpad = start[i] + crop_size[i] - imgs.shape[i + 1]\n",
    "            else:\n",
    "                rightpad = 0\n",
    "\n",
    "            pad.append([leftpad, rightpad])\n",
    "\n",
    "        imgs = np.pad(imgs, pad, 'constant', constant_values=self.filling_value)\n",
    "        crop = imgs[:, start[0]:start[0] + crop_size[0], start[1]:start[1] + crop_size[1],\n",
    "               start[2]:start[2] + crop_size[2]]\n",
    "\n",
    "        normstart = np.array(start).astype('float32') / np.array(imgs.shape[1:]) - 0.5\n",
    "        normsize = np.array(crop_size).astype('float32') / np.array(imgs.shape[1:])\n",
    "        xx, yy, zz = np.meshgrid(np.linspace(normstart[0], normstart[0] + normsize[0], self.crop_size[0] / self.stride),\n",
    "                                 np.linspace(normstart[1], normstart[1] + normsize[1], self.crop_size[1] / self.stride),\n",
    "                                 np.linspace(normstart[2], normstart[2] + normsize[2], self.crop_size[2] / self.stride),\n",
    "                                 indexing='ij')\n",
    "        coord = np.concatenate([xx[np.newaxis, ...], yy[np.newaxis, ...], zz[np.newaxis, :]], 0).astype('float32')\n",
    "\n",
    "        return crop, coord\n",
    "\n",
    "\n",
    "def predict(image_itk, nodule_list, model_path=\"src/algorithms/classify/assets/gtr123_model.ckpt\"):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      image_itk: ITK dicom image\n",
    "      nodule_list: List of nodules\n",
    "      model_path: Path to the torch model (Default value = \"src/algorithms/classify/assets/gtr123_model.ckpt\")\n",
    "\n",
    "    Returns:\n",
    "      List of nodules, and probabilities\n",
    "\n",
    "    \"\"\"\n",
    "    if not nodule_list:\n",
    "        return []\n",
    "    casenet = CaseNet()\n",
    "\n",
    "    casenet.load_state_dict(torch.load(model_path))\n",
    "    casenet.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        casenet = torch.nn.DataParallel(casenet).cuda()\n",
    "        # else:\n",
    "        # casenet = torch.nn.parallel.DistributedDataParallel(casenet)\n",
    "\n",
    "    image = sitk.GetArrayFromImage(image_itk)\n",
    "    spacing = np.array(image_itk.GetSpacing())[::-1]\n",
    "    image = lum_trans(image)\n",
    "    image = resample(image, spacing, np.array([1, 1, 1]), order=1)[0]\n",
    "\n",
    "    crop = SimpleCrop()\n",
    "\n",
    "    results = []\n",
    "    for nodule in nodule_list:\n",
    "        print(nodule)\n",
    "        nod_location = np.array([np.float32(nodule[s]) for s in [\"z\", \"y\", \"x\"]])\n",
    "        nod_location *= spacing\n",
    "        cropped_image, coords = crop(image[np.newaxis], nod_location)\n",
    "        cropped_image = Variable(torch.from_numpy(cropped_image[np.newaxis]).float())\n",
    "        cropped_image.volatile = True\n",
    "        coords = Variable(torch.from_numpy(coords[np.newaxis]).float())\n",
    "        coords.volatile = True\n",
    "        _, pred, _ = casenet(cropped_image, coords)\n",
    "        results.append(\n",
    "            {\"x\": nodule[\"x\"], \"y\": nodule[\"y\"], \"z\": nodule[\"z\"], \"p_concerning\": float(pred.data.cpu().numpy())})\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "\"\"\"\n",
    "Preprocessing tools used by the gtr123_models\n",
    "Code adapted from https://github.com/lfz/DSB2017\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def lum_trans(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      img:  Input image in Hu units\n",
    "\n",
    "    Returns: Image windowed to [-1200; 600] and scaled to 0-255\n",
    "\n",
    "    \"\"\"\n",
    "    lungwin = np.array([-1200., 600.])\n",
    "    newimg = (img - lungwin[0]) / (lungwin[1] - lungwin[0])\n",
    "    newimg[newimg < 0] = 0\n",
    "    newimg[newimg > 1] = 1\n",
    "    return (newimg * 255).astype('uint8')\n",
    "\n",
    "\n",
    "def resample(imgs, spacing, new_spacing, order=2):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      imgs:\n",
    "      spacing: Input image voxel size\n",
    "      new_spacing: Output image voxel size\n",
    "      order:  (Default value = 2)\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if len(imgs.shape) == 3:\n",
    "        new_shape = np.round(imgs.shape * spacing / new_spacing)\n",
    "        true_spacing = spacing * imgs.shape / new_shape\n",
    "        resize_factor = new_shape / imgs.shape\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imgs = zoom(imgs, resize_factor, mode='nearest', order=order)\n",
    "\n",
    "        return imgs, true_spacing\n",
    "    elif len(imgs.shape) == 4:\n",
    "        n = imgs.shape[-1]\n",
    "        newimg = []\n",
    "\n",
    "        for i in range(n):\n",
    "            slice = imgs[:, :, :, i]\n",
    "            newslice, true_spacing = resample(slice, spacing, new_spacing)\n",
    "            newimg.append(newslice)\n",
    "\n",
    "        newimg = np.transpose(np.array(newimg), [1, 2, 3, 0])\n",
    "        return newimg, true_spacing\n",
    "    else:\n",
    "        raise ValueError('wrong shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
